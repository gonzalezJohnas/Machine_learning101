{
 "cells": [
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": true
   },
   "level": 1,
   "source": []
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Learning to predict who survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_cat</th>\n",
       "      <th>Sex_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_cat</th>\n",
       "      <th>Sex_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./dataset/titanic/cleaned_train.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data in train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:].values\n",
    "Y = dataset.iloc[:, 0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train set: 569\nLength test set: 143\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"Length train set: {}\".format(len(X_train)))\n",
    "print(\"Length test set: {}\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test different machine learning models with our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]Logistic Regression Training Accuracy: 0.8031634446397188\n[1]K Nearest Neighbor Training Accuracy: 0.789103690685413\n[2]Support Vector Machine (Linear Classifier) Training Accuracy: 0.7768014059753954\n[3]Support Vector Machine (RBF Classifier) Training Accuracy: 0.9173989455184535\n[4]Gaussian Naive Bayes Training Accuracy: 0.8031634446397188\n[5]Decision Tree Classifier Training Accuracy: 0.9929701230228472\n[6]Random Forest Classifier Training Accuracy: 0.984182776801406\n"
     ]
    }
   ],
   "source": [
    "#Create a function within many Machine Learning Models\n",
    "def models(X_train,Y_train):\n",
    "  \n",
    "  #Using Logistic Regression Algorithm to the Training Set\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  log = LogisticRegression(random_state = 0, solver='liblinear')\n",
    "  log.fit(X_train, Y_train)\n",
    "  \n",
    "  #Using KNeighborsClassifier Method of neighbors class to use Nearest Neighbor algorithm\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "  knn.fit(X_train, Y_train)\n",
    "\n",
    "  #Using SVC method of svm class to use Support Vector Machine Algorithm\n",
    "  from sklearn.svm import SVC\n",
    "  svc_lin = SVC(kernel = 'linear', random_state = 0)\n",
    "  svc_lin.fit(X_train, Y_train)\n",
    "\n",
    "  #Using SVC method of svm class to use Kernel SVM Algorithm\n",
    "  from sklearn.svm import SVC\n",
    "  svc_rbf = SVC(kernel = 'rbf', random_state = 0, gamma='auto')\n",
    "  svc_rbf.fit(X_train, Y_train)\n",
    "\n",
    "  #Using GaussianNB method of naïve_bayes class to use Naïve Bayes Algorithm\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  gauss = GaussianNB()\n",
    "  gauss.fit(X_train, Y_train)\n",
    "\n",
    "  #Using DecisionTreeClassifier of tree class to use Decision Tree Algorithm\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "  tree.fit(X_train, Y_train)\n",
    "\n",
    "  #Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  forest = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 0)\n",
    "  forest.fit(X_train, Y_train)\n",
    "  \n",
    "  #print model accuracy on the training data.\n",
    "  print('[0]Logistic Regression Training Accuracy:', log.score(X_train, Y_train))\n",
    "  print('[1]K Nearest Neighbor Training Accuracy:', knn.score(X_train, Y_train))\n",
    "  print('[2]Support Vector Machine (Linear Classifier) Training Accuracy:', svc_lin.score(X_train, Y_train))\n",
    "  print('[3]Support Vector Machine (RBF Classifier) Training Accuracy:', svc_rbf.score(X_train, Y_train))\n",
    "  print('[4]Gaussian Naive Bayes Training Accuracy:', gauss.score(X_train, Y_train))\n",
    "  print('[5]Decision Tree Classifier Training Accuracy:', tree.score(X_train, Y_train))\n",
    "  print('[6]Random Forest Classifier Training Accuracy:', forest.score(X_train, Y_train))\n",
    "  \n",
    "  return log, knn, svc_lin, svc_rbf, gauss, tree, forest\n",
    "\n",
    "\n",
    "model = models(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test our model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\nAccuracy: 0.8041958041958042\nClassification report\n              precision    recall  f1-score   support\n\n           0       0.79      0.89      0.84        82\n           1       0.82      0.69      0.75        61\n\n   micro avg       0.80      0.80      0.80       143\n   macro avg       0.81      0.79      0.79       143\nweighted avg       0.81      0.80      0.80       143\n\n#####################################################\nModel: knn\nAccuracy: 0.6643356643356644\nClassification report\n              precision    recall  f1-score   support\n\n           0       0.68      0.78      0.73        82\n           1       0.63      0.51      0.56        61\n\n   micro avg       0.66      0.66      0.66       143\n   macro avg       0.66      0.64      0.65       143\nweighted avg       0.66      0.66      0.66       143\n\n#####################################################\nModel: svc_lin\nAccuracy: 0.7902097902097902\nClassification report\n              precision    recall  f1-score   support\n\n           0       0.80      0.85      0.82        82\n           1       0.78      0.70      0.74        61\n\n   micro avg       0.79      0.79      0.79       143\n   macro avg       0.79      0.78      0.78       143\nweighted avg       0.79      0.79      0.79       143\n\n#####################################################\nModel: svc_rbf\nAccuracy: 0.6433566433566433\nClassification report\n              precision    recall  f1-score   support\n\n           0       0.65      0.83      0.73        82\n           1       0.63      0.39      0.48        61\n\n   micro avg       0.64      0.64      0.64       143\n   macro avg       0.64      0.61      0.61       143\nweighted avg       0.64      0.64      0.62       143\n\n#####################################################\nModel: gauss\nAccuracy: 0.7482517482517482\nClassification report\n              precision    recall  f1-score   support\n\n           0       0.75      0.84      0.79        82\n           1       0.75      0.62      0.68        61\n\n   micro avg       0.75      0.75      0.75       143\n   macro avg       0.75      0.73      0.74       143\nweighted avg       0.75      0.75      0.74       143\n\n#####################################################\nModel: tree\nAccuracy: 0.7762237762237763\nClassification report\n              precision    recall  f1-score   support\n\n           0       0.86      0.73      0.79        82\n           1       0.70      0.84      0.76        61\n\n   micro avg       0.78      0.78      0.78       143\n   macro avg       0.78      0.78      0.78       143\nweighted avg       0.79      0.78      0.78       143\n\n#####################################################\nModel: forest\nAccuracy: 0.8251748251748252\nClassification report\n              precision    recall  f1-score   support\n\n           0       0.84      0.87      0.85        82\n           1       0.81      0.77      0.79        61\n\n   micro avg       0.83      0.83      0.83       143\n   macro avg       0.82      0.82      0.82       143\nweighted avg       0.82      0.83      0.82       143\n\n#####################################################\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score \n",
    "models_name = ['Logistic Regression', 'knn', 'svc_lin', 'svc_rbf', 'gauss', 'tree', 'forest']\n",
    "\n",
    "for i in range(len(model)):\n",
    "    \n",
    "    y_predic = model[i].predict(X_test)\n",
    "\n",
    "    report = classification_report(Y_test, y_predic)\n",
    "    print('Model: {}'.format(models_name[i]))\n",
    "    print('Accuracy: {}'.format(accuracy_score(Y_test, y_predic)))\n",
    "    print(\"Classification report\")\n",
    "    print(report)\n",
    "    print('#####################################################')# Print a new line\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Training Accuracy: 80.06064162754302% (5.608055856387823%)\nRandom Forest Classifier Training Precision: 77.8193564355967% (8.3944425357888%)\nRandom Forest Classifier Training Recall: 70.12711312092871% (9.803484981326035%)\n##################################################################\n\nDecision Tree Classifier Training Accuracy: 76.40062597809077% (5.425554737429664%)\nDecision Tree Classifier Training Precision: 70.64792893604701% (8.35740062008114%)\nDecision Tree Classifier Training Recall: 71.02120972342112% (7.781584002116166%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "#Create a function within many Machine Learning Models\n",
    "\n",
    "    \n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score)}\n",
    "\n",
    "#Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=20, criterion='entropy', random_state=0)\n",
    "tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "\n",
    "results_kfold_forest = cross_validate(forest.fit(X,Y), X, Y, cv=kf, scoring=scoring)\n",
    "results_kfold_tree = cross_validate(tree.fit(X,Y), X, Y, cv=kf, scoring=scoring)\n",
    "\n",
    "# print model accuracy on the training data.\n",
    "print('Random Forest Classifier Training Accuracy: {}% ({}%)'.format(results_kfold_forest['test_accuracy'].mean() * 100.0, results_kfold_forest['test_accuracy'].std() * 100.0))\n",
    "print('Random Forest Classifier Training Precision: {}% ({}%)'.format(results_kfold_forest['test_precision'].mean() * 100.0, results_kfold_forest['test_precision'].std() * 100.0))\n",
    "print('Random Forest Classifier Training Recall: {}% ({}%)'.format(results_kfold_forest['test_recall'].mean() * 100.0, results_kfold_forest['test_recall'].std() * 100.0))\n",
    "\n",
    "print('##################################################################')\n",
    "print()\n",
    "\n",
    "print('Decision Tree Classifier Training Accuracy: {}% ({}%)'.format(results_kfold_tree['test_accuracy'].mean() * 100.0, results_kfold_tree['test_accuracy'].std() * 100.0))\n",
    "print('Decision Tree Classifier Training Precision: {}% ({}%)'.format(results_kfold_tree['test_precision'].mean() * 100.0, results_kfold_tree['test_precision'].std() * 100.0))\n",
    "print('Decision Tree Classifier Training Recall: {}% ({}%)'.format(results_kfold_tree['test_recall'].mean() * 100.0, results_kfold_tree['test_recall'].std() * 100.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
